{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/osmi/mental-health-in-tech-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=0.5)\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 150\n",
    "\n",
    "df = pd.read_csv('data/mental.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = ['is_self_employed', 'employee_count_bracket', 'is_tech_org', 'role_is_IT', 'empl_provides_mh_cov', 'knows_mh_cov_options',\n",
    "                    'empl_discussed_mh','empl_offers_mh_rsrcs','anon_protec','if_askfor_mh_medical_leave_how_easy', 'discuss_mh_with_empl_wouldcause_neg_conseq', 'discuss_ph_with_empl_wouldcause_neg_conseq',\n",
    "                    'comfy_discussing_mh_with_coworkers','comfy_discussing_mh_with_supervisors' , 'empl_takes_mh_asseriously_as_ph', 'observed_neg_conseq_for_coworkers_openabout_mh_inworkspace',\n",
    "                    'has_medical_cov_incl_mh', 'knowsof_mh_resources','if_diag_would_reveal_toclients/bn_contacts', 'if_reveal_diag_toclient_didthis_impact_neg', 'if_diag_would_reveal_tocoworkers/employees',\n",
    "                    'if_reveal_diag_tocoworker_didthis_impact_neg', 'productivity_isaffected_by_mh', 'percentage_worktime_affected_by_mh', 'has_prev_employers','prev_empl_provided_mh_benefits',\n",
    "                    'was_aware_of_prevemployers_mhcare_options','prev_empl_discussed_mh', 'prev_empl_provided_mh_rsrc', 'prev_anon_protec', 'prev_discuss_mh_with_empl_wouldcause_neg_conseq',\n",
    "                    'prev_discuss_ph_with_empl_wouldcause_neg_conseq', 'prev_wouldhavebeen_willing_discuss_mh_coworkers', 'prev_wouldhavebeen_willing_discuss_mh_supervisors',\n",
    "                    'prev_empl_takes_mh_asseriously_as_ph', 'prev_observed_neg_conseq_for_coworkers_openabout_mh_inworkspace', 'willingto_bringup_ph_interview', 'why', 'willingto_bringup_mh_interview',\n",
    "                    'why2', 'believes_beingident_as_mh_wouldhurt_career', 'thinks_coworkers_wouldviewthem_neg_if_mh', 'howwilling_share_mh_with_friendsfamily',\n",
    "                    'observed_badly_handled_response_to_mh_inworkplace', 'observed_madethem_notwantto_talk_about_mh', 'has_family_history_mh', 'hashad_mh_inpast', 'HAS_MH', 'diagnoses_notprof',\n",
    "                    'conditions_suspected', 'hasbeen_diag_byprof', 'diagnoses_prof', 'sought_treatment', 'mh_interferes_w/work_effective_trt', 'mh_interferes_w/work_ineffective_trt',\n",
    "                    'age', 'sex', 'country_livesin', 'us_state_livesin', 'country_worksin', 'us_state_worksin', 'work_position', 'is_remote_working']\n",
    "\n",
    "df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dropping stuff\"\"\"\n",
    "\n",
    "\n",
    "why_cols = [columns for columns in df.columns if 'why' in columns]\n",
    "\n",
    "#dropping 'why' questions, as each one of them is too unique\n",
    "for column in why_cols:\n",
    "    df.drop(column, axis='columns', inplace=True)\n",
    "\n",
    "#most people (all but 26) work in the same country as they live. this info will still be preserved in remote working column. dropping the country_livesin_column\n",
    "df.drop('country_livesin', axis='columns', inplace=True)\n",
    "\n",
    "#1. US state is not informative, 2. This analysis won't focus on particular MH conditions, as they will explode the dataset\n",
    "df.drop(['us_state_livesin', 'us_state_worksin', 'diagnoses_prof'], axis='columns', inplace=True)\n",
    "\n",
    "#dropping columns with clear majority missing values\n",
    "df.drop(['knowsof_mh_resources', 'if_diag_would_reveal_toclients/bn_contacts', 'if_reveal_diag_toclient_didthis_impact_neg', 'if_diag_would_reveal_tocoworkers/employees', 'if_reveal_diag_tocoworker_didthis_impact_neg',\n",
    "         'productivity_isaffected_by_mh','percentage_worktime_affected_by_mh'], axis='columns', inplace=True)\n",
    "\n",
    "#dropping non-professional and self-diagnoses - 1. because mostly are missing anyway and 2. self diagnoses can be very innaccurate\n",
    "df.drop(['diagnoses_notprof', 'conditions_suspected'], axis='columns', inplace=True)\n",
    "\n",
    "#dropping the columns for the majority answer \"I don't know\"\n",
    "df.drop(['empl_takes_mh_asseriously_as_ph', 'anon_protec', 'prev_anon_protec'], axis='columns', inplace=True)\n",
    "\n",
    "#dropping this because 1. most responses are 'Not applicable',\n",
    "#2. The column with ineffective treatment is more informative towards the insights we want to gain\n",
    "df.drop('mh_interferes_w/work_effective_trt', axis='columns', inplace=True)\n",
    "\n",
    "#most do not know about their past employers coverage options\n",
    "df.drop('was_aware_of_prevemployers_mhcare_options', axis='columns', inplace=True)\n",
    "\n",
    "#uninformative, most have not observed\n",
    "df.drop('observed_neg_conseq_for_coworkers_openabout_mh_inworkspace', axis='columns', inplace=True)\n",
    "\n",
    "#Highly correlated with HAS_MH column - doesn't carry additional info\n",
    "df.drop('hashad_mh_inpast', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing gender names to a male/female/other convention\n",
    "df['sex'].replace(to_replace=['Male', 'male', 'Male ','M','m','man','Male.','male 9:1 female, roughly','Male (cis)','Sex is male','Man',\n",
    "                              'cis male','Malr','Dude',\"I'm a man why didn't you make this a drop down question. You should of asked sex? And I would of answered yes please. Seriously how much text can this take? \",\n",
    "                              'mail', 'M|', 'Male/genderqueer','male ','Cis Male', 'Male (trans, FtM)','cisdude','cis man','MALE','Cis male'], value='MALE', inplace=True)\n",
    "\n",
    "df['sex'].replace(to_replace=['Female', 'female', 'I identify as female.','female ','Female assigned at birth ','F', 'Woman', 'fm', 'f', 'Cis female ', 'Transitioned, M2F',\n",
    "                                        'Female or Multi-Gender Femme', 'Female ', 'woman', 'female/woman','Cisgender Female','genderqueer woman','mtf','fem', 'Female (props for making this a freeform field, though)',\n",
    "                                        ' Female','Cis-woman','Transgender woman'\n",
    "                                        ],value='FEMALE', inplace=True)\n",
    "\n",
    "df['sex'].replace(to_replace=['Bigender', 'non-binary',\n",
    "       'Genderfluid (born female)', 'Other/Transfeminine', 'Androgynous', 'Other', 'nb masculine', 'none of your business',\n",
    "       'genderqueer', 'Human', 'Genderfluid', 'Enby', 'Queer', 'Agender',\n",
    "       'Fluid', 'Nonbinary', 'human', 'Unicorn', 'Genderqueer',\n",
    "       'Genderflux demi-girl', 'female-bodied; no feelings about gender',\n",
    "       'AFAB'], value='OTHER', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print(df[column].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#majority from USA, UK, CD, GER, NED, AUS - dropping others for now\n",
    "df = df.loc[df['country_worksin'].isin(['United States of America', 'United Kingdom', 'Canada', 'Germany', 'Netherlands', 'Australia'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_tech_role(row):\n",
    "    \n",
    "    tech_roles = ['Back-end Developer', 'Front-end Developer','DevOps/SysAdmin', 'Dev Evangelist/Advocate']\n",
    "    \n",
    "    for role in tech_roles:\n",
    "        if role in row['work_position']:\n",
    "            return 'Yes'\n",
    "    \n",
    "    return 'No'\n",
    "\n",
    "df['has_tech_role'] = df.apply(lambda row: has_tech_role(row), axis=1)\n",
    "df.drop('role_is_IT', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_bracket(row):\n",
    "    bracket = row['employee_count_bracket']\n",
    "    \n",
    "    if bracket in ['1-5', '6-25']:\n",
    "        return '1-25'\n",
    "    \n",
    "    elif bracket in ['26-100', '100-500']:\n",
    "        return '26-500'\n",
    "    \n",
    "    elif bracket in ['500-1000', 'More than 1000']:\n",
    "        return '500 or more'\n",
    "    \n",
    "    else:\n",
    "        return bracket\n",
    "        \n",
    "\n",
    "df['employee_count_bracket'] = df.apply(lambda row: get_new_bracket(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns that will have missing values for self-employed respondents (209 people)\n",
    "excluded_for_self_employed = ['employee_count_bracket', 'empl_provides_mh_cov', 'is_tech_org', 'empl_discussed_mh', 'empl_offers_mh_rsrcs',\n",
    "                            'if_askfor_mh_medical_leave_how_easy', 'discuss_mh_with_empl_wouldcause_neg_conseq',\n",
    "                              'discuss_ph_with_empl_wouldcause_neg_conseq', 'comfy_discussing_mh_with_coworkers', \n",
    "                              'comfy_discussing_mh_with_supervisors', 'observed_badly_handled_response_to_mh_inworkplace']\n",
    "\n",
    "#columns that will have missing values for respondents with no previous employers (104 people)\n",
    "excluded_for_no_prev_employers = ['prev_empl_provided_mh_benefits', 'prev_empl_discussed_mh', 'prev_empl_provided_mh_rsrc',\n",
    "                                  'prev_discuss_mh_with_empl_wouldcause_neg_conseq', 'prev_discuss_ph_with_empl_wouldcause_neg_conseq',\n",
    "                                  'prev_wouldhavebeen_willing_discuss_mh_coworkers', 'prev_wouldhavebeen_willing_discuss_mh_supervisors', 'prev_empl_takes_mh_asseriously_as_ph',\n",
    "                                  'prev_observed_neg_conseq_for_coworkers_openabout_mh_inworkspace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the relevant missing values with 'N/A' - not applicable\n",
    "df.loc[df['is_self_employed'] == 1,       excluded_for_self_employed] = df.loc[df['is_self_employed'] == 1, excluded_for_self_employed].fillna(\"N/A\")\n",
    "df.loc[df['has_prev_employers'] == 0, excluded_for_no_prev_employers] = df.loc[df['has_prev_employers'] == 0, excluded_for_no_prev_employers].fillna(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in the 3 remaining with male - safest bet as the overwhelming majority of the respondents are male\n",
    "df.loc[pd.isna(df['sex']), 'sex'] = df.loc[pd.isna(df['sex']), 'sex'].fillna('MALE')\n",
    "\n",
    "#assuming the 323 age is a typo on 32\n",
    "df.loc[df['age'] == 323, 'age'] = 32\n",
    "\n",
    "#assuming the 3 age is a typo also, filling it in with 30, as it's the mode\n",
    "df.loc[df['age'] == 3, 'age'] = 30\n",
    "\n",
    "#I really doubt this person is 99\n",
    "df.loc[df['age'] == 99, 'age'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_cov_yes_filt = (pd.isna(df['has_medical_cov_incl_mh'])) & (df['empl_provides_mh_cov'] == 'Yes')\n",
    "\n",
    "#Filling in the missing values for medical coverage - if the employer provides it, means they have it\n",
    "#df.loc[empl_cov_yes_filt, \"has_medical_cov_incl_mh\" ] = df.loc[empl_cov_yes_filt, \"has_medical_cov_incl_mh\" ].fillna(1.0)\n",
    "\n",
    "#dropping med coverage for now and remaining missing val columns- even with the above commented out step, we still end up with almost 500 missing values\n",
    "df.drop(['has_medical_cov_incl_mh', 'knows_mh_cov_options', 'observed_madethem_notwantto_talk_about_mh'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING WORK POSITION FOR NOW\n",
    "df.drop('work_position', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is replacing some of the survey answers with more general ones - we do this because it increases the variance in the respective columns while preserving the underlying information\n",
    "#A lot of the possible answers, while being different, carry barely any additional useful info as well as blowing up the number of columns after OHE\n",
    "\n",
    "df['prev_empl_provided_mh_benefits'].replace({'Some did': 'Some or all did', 'Yes, they all did': 'Some or all did'}, inplace=True)\n",
    "df['if_askfor_mh_medical_leave_how_easy'].replace({'Somewhat easy': 'Easy', 'Very easy': 'Easy', 'Somewhat difficult': 'Difficult', 'Very difficult': 'Difficult'}, inplace=True)\n",
    "df['prev_empl_discussed_mh'].replace({'Some did': 'Some or all did', 'Yes, they all did': 'Some or all did'}, inplace=True)\n",
    "df['prev_empl_provided_mh_rsrc'].replace({'Some did': 'Some or all did', 'Yes, they all did': 'Some or all did'}, inplace=True)\n",
    "df['prev_discuss_mh_with_empl_wouldcause_neg_conseq'].replace({'Some of them': 'Some or all of them', 'Yes, all of them': 'Some or all of them'}, inplace=True)\n",
    "df['prev_discuss_ph_with_empl_wouldcause_neg_conseq'].replace({'Some of them': 'Some or all of them', 'Yes, all of them': 'Some or all of them'}, inplace=True)\n",
    "df['prev_wouldhavebeen_willing_discuss_mh_coworkers'].replace({'Some of my previous employers': 'Some or all of my previous employers', 'Yes, at all of my previous employers': 'Some or all of my previous employers'}, inplace=True)\n",
    "df['prev_wouldhavebeen_willing_discuss_mh_supervisors'].replace({'Some of my previous employers': 'Some or all of my previous employers', 'Yes, at all of my previous employers': 'Some or all of my previous employers'}, inplace=True)\n",
    "df['prev_empl_takes_mh_asseriously_as_ph'].replace({'Some did': 'Some or all did', 'Yes, they all did': 'Some or all did'}, inplace=True)\n",
    "df['prev_observed_neg_conseq_for_coworkers_openabout_mh_inworkspace'].replace({'Some of them': 'Some or all of them', 'Yes, all of them': 'Some or all of them'}, inplace=True)\n",
    "df['believes_beingident_as_mh_wouldhurt_career'].replace({'Yes, it has': 'Yes, I think it would', 'No, it has not': \"No, I don't think it would\"}, inplace=True)\n",
    "df['thinks_coworkers_wouldviewthem_neg_if_mh'].replace({'No, they do not': \"No, I don't think they would\", 'Yes, they do': 'Yes, I think they would'}, inplace=True)\n",
    "df['howwilling_share_mh_with_friendsfamily'].replace({'Somewhat open': 'Open', 'Very open': 'Open', 'Somewhat not open': 'Not open', 'Not open at all': 'Not open'}, inplace=True)\n",
    "df['mh_interferes_w/work_ineffective_trt'].replace({'Never': 'Rarely'}, inplace=True)\n",
    "df['observed_badly_handled_response_to_mh_inworkplace'].replace({'Yes, I observed': 'Yes, I observed or experienced', 'Yes, I experienced': 'Yes, I observed or experienced'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_tech_org'].replace({0.0: 'No', 1.0: 'Yes'}, inplace=True)\n",
    "df['is_self_employed'].replace({0: 'No', 1: 'Yes'}, inplace=True)\n",
    "df['has_prev_employers'].replace({0: 'No', 1: 'Yes'}, inplace=True)\n",
    "df['sought_treatment'].replace({0: 'No', 1: 'Yes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comfy_ppl_atwork(row):\n",
    "    comfy_with_coworkers   = row['comfy_discussing_mh_with_coworkers']\n",
    "    comfy_with_supervisors = row['comfy_discussing_mh_with_supervisors']\n",
    "    \n",
    "    if comfy_with_coworkers == comfy_with_supervisors:\n",
    "        return comfy_with_supervisors\n",
    "    \n",
    "    elif {comfy_with_supervisors, comfy_with_coworkers} == {'Yes', 'Maybe'}:\n",
    "        return 'Maybe'\n",
    "\n",
    "    else:\n",
    "        return comfy_with_supervisors\n",
    "    \n",
    "def get_willing_discuss_mh_ppl_prevjob(row):\n",
    "    comfy_with_prev_coworkers = row['prev_wouldhavebeen_willing_discuss_mh_coworkers']\n",
    "    comfy_with_prev_supervisors = row['prev_wouldhavebeen_willing_discuss_mh_supervisors']\n",
    "    \n",
    "    if comfy_with_prev_coworkers == comfy_with_prev_supervisors:\n",
    "        return comfy_with_prev_coworkers\n",
    "    \n",
    "    else:\n",
    "        return comfy_with_prev_supervisors\n",
    "\n",
    "#this dilutes these 2 columns a bit, but dimensionality reduction here is priority\n",
    "df['comfy_discussing_mh_with_ppl_atwork'] = df.apply(lambda row: get_comfy_ppl_atwork(row), axis=1)\n",
    "df['prev_comfy_discussing_mh_with_ppl_atwork'] = df.apply(lambda row: get_willing_discuss_mh_ppl_prevjob(row), axis=1)\n",
    "\n",
    "df.drop(['comfy_discussing_mh_with_supervisors', 'comfy_discussing_mh_with_coworkers',\n",
    "         'prev_wouldhavebeen_willing_discuss_mh_coworkers', 'prev_wouldhavebeen_willing_discuss_mh_supervisors'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_c = 'discuss_ph_with_empl_wouldcause_neg_conseq'\n",
    "mh_c = 'discuss_mh_with_empl_wouldcause_neg_conseq'\n",
    "\n",
    "df.groupby(ph_c)[mh_c].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will answer the question - does the respondent feel it is more likely that discussing mh will cause negative consequences\n",
    "#compared to ph?\n",
    "\n",
    "def conseq_morelikely_mh_compared_ph(row):\n",
    "    conseq_mh = row['discuss_mh_with_empl_wouldcause_neg_conseq']\n",
    "    conseq_ph = row['discuss_ph_with_empl_wouldcause_neg_conseq']\n",
    "\n",
    "    if conseq_ph == 'N/A' or conseq_mh == 'N/A':\n",
    "        return 'N/A'\n",
    "    \n",
    "    elif conseq_ph == conseq_mh:\n",
    "        return 'No'\n",
    "    \n",
    "    elif conseq_ph == 'No' and conseq_mh in ['Maybe', 'Yes']:\n",
    "        return 'Yes'\n",
    "    \n",
    "    elif conseq_ph == 'Maybe' and conseq_mh == 'Yes':\n",
    "        return 'Yes'\n",
    "\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "\n",
    "#Same as above but for previous employers\n",
    "def prev_conseq_morelikely_mh_compared_ph(row):\n",
    "    prev_conseq_mh = row['prev_discuss_mh_with_empl_wouldcause_neg_conseq']\n",
    "    prev_conseq_ph = row['prev_discuss_ph_with_empl_wouldcause_neg_conseq']\n",
    "\n",
    "    if prev_conseq_ph == 'N/A' or prev_conseq_mh == 'N/A':\n",
    "        return 'N/A'\n",
    "    \n",
    "    elif prev_conseq_ph == prev_conseq_mh:\n",
    "        return 'No'\n",
    "\n",
    "    #One can argue that if they're sure about no consequences for ph, and don't know for mh, they feel it was more likely to suffer negative conseq\n",
    "    #for sharing mental health issues\n",
    "    elif prev_conseq_ph == 'None of them' and prev_conseq_mh in ['Some or all of them', \"I don't know\"]:\n",
    "        return 'Yes'\n",
    "    \n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "\n",
    "df['morelikely_neg_conseq_for_mh_comparedto_ph']      = df.apply(lambda row: conseq_morelikely_mh_compared_ph(row), axis=1)\n",
    "df['prev_morelikely_neg_conseq_for_mh_comparedto_ph'] = df.apply(lambda row: prev_conseq_morelikely_mh_compared_ph(row), axis=1)\n",
    "\n",
    "df.drop(['discuss_mh_with_empl_wouldcause_neg_conseq', 'discuss_ph_with_empl_wouldcause_neg_conseq',\n",
    "         'prev_discuss_mh_with_empl_wouldcause_neg_conseq', 'prev_discuss_ph_with_empl_wouldcause_neg_conseq'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "willing_ph = 'willingto_bringup_ph_interview'\n",
    "willing_mh = 'willingto_bringup_mh_interview'\n",
    "\n",
    "df.groupby(willing_ph)[willing_mh].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morelikely_tobringup_ph_over_mh_interview(row):\n",
    "    willing_ph = row['willingto_bringup_ph_interview']\n",
    "    willing_mh = row['willingto_bringup_mh_interview']\n",
    "\n",
    "    if willing_ph == willing_mh:\n",
    "        return 'No'\n",
    "    \n",
    "    elif willing_ph == 'Maybe' and willing_mh == 'No':\n",
    "        return 'Yes'\n",
    "    \n",
    "    elif willing_ph == 'Yes' and willing_mh  in ['Maybe', 'No']:\n",
    "        return 'Yes'\n",
    "        \n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "\n",
    "df['morelikely_tobringup_ph_over_mh_interview'] = df.apply(lambda row: morelikely_tobringup_ph_over_mh_interview(row), axis=1)\n",
    "df.drop(columns=['willingto_bringup_ph_interview', 'willingto_bringup_mh_interview'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['observed_badly_handled_response_to_mh_inworkplace'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uninformative, most are tech org\n",
    "df.drop(columns =['employee_count_bracket', 'is_tech_org'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed = df.loc[df['is_self_employed'] == 'No'].copy()\n",
    "\n",
    "self_employed = df.loc[df['is_self_employed'] == 'Yes'].copy()\n",
    "\n",
    "employed_with_prev = employed.loc[employed['has_prev_employers'] == 'Yes'].copy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excluded_self_empl = ['empl_provides_mh_cov', 'empl_discussed_mh', 'empl_offers_mh_rsrcs',\n",
    "                          'if_askfor_mh_medical_leave_how_easy', 'comfy_discussing_mh_with_ppl_atwork', 'morelikely_neg_conseq_for_mh_comparedto_ph',\n",
    "                          'observed_badly_handled_response_to_mh_inworkplace', 'is_self_employed']\n",
    "\n",
    "self_employed.drop(columns = new_excluded_self_empl, inplace=True)\n",
    "employed.drop('is_self_employed', axis='columns', inplace=True)\n",
    "employed_with_prev.drop('has_prev_employers', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def ohe_encode(df, cat_df):\n",
    "\n",
    "    ohe = OneHotEncoder(drop='if_binary')\n",
    "\n",
    "    ct = ColumnTransformer(\n",
    "        transformers=[('encoder', ohe, cat_df.columns)],\n",
    "        remainder='passthrough' \n",
    "    )\n",
    "\n",
    "    encoded_data = ct.fit_transform(df)\n",
    "    feature_names = ct.get_feature_names_out()\n",
    "\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=feature_names)\n",
    "\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_categorical = employed.drop('age', axis='columns')\n",
    "employed_encoded = ohe_encode(employed, employed_categorical)\n",
    "\n",
    "employed_with_prev_categorical = employed_with_prev.drop('age', axis='columns')\n",
    "employed_with_prev_encoded = ohe_encode(employed_with_prev, employed_with_prev_categorical)\n",
    "\n",
    "self_employed_categorical = self_employed.drop('age', axis='columns')\n",
    "self_employed_encoded = ohe_encode(self_employed, self_employed_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_with_prev_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def scale_age(encoded_df):\n",
    "    scaled_age = StandardScaler().fit_transform(encoded_df['remainder__age'].array.reshape(-1,1))\n",
    "\n",
    "    encoded_df.drop('remainder__age', axis='columns', inplace=True)\n",
    "    encoded_df['scaled_age'] = scaled_age\n",
    "\n",
    "\n",
    "for encoded_df in [employed_encoded, employed_with_prev_encoded, self_employed_encoded]:\n",
    "    scale_age(encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_features(df, correlation_threshold):\n",
    "\n",
    "    correlated_features = []\n",
    "\n",
    "    correlation_matrix = df.corr(method='spearman')\n",
    "\n",
    "    # Iterate through the correlation matrix\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            # Check if the correlation coefficient exceeds the threshold\n",
    "            if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "                correlated_features.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "    return correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def get_variance_thr_df(df, threshold):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "\n",
    "    new = selector.fit_transform(df)\n",
    "\n",
    "    features = selector.get_support(indices=True)\n",
    "    columns = df.columns[features]\n",
    "\n",
    "    return pd.DataFrame(new, columns=columns)\n",
    "\n",
    "employed_selected = get_variance_thr_df(employed_encoded, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_pca_df(encoded_df, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    pca.fit(encoded_df)\n",
    "    print(pca.explained_variance_ratio_.sum())\n",
    "\n",
    "    return pd.DataFrame(pca.fit_transform(encoded_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_pca_df = get_pca_df(employed_encoded, n_components=25)\n",
    "employed_with_prev_pca_df = get_pca_df(employed_with_prev_encoded, n_components=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_pca_for_tsne_df = get_pca_df(employed_encoded, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=50, random_state=20)\n",
    "\n",
    "empl_tsne_df = pd.DataFrame(tsne.fit_transform(empl_pca_for_tsne_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(empl_tsne_df[0], empl_tsne_df[1], s = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_kmeans = KMeans(n_clusters=3, n_init='auto')\n",
    "tsne_kmeans_labels = tsne_kmeans.fit_predict(empl_tsne_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clustering_scores(df_to_cluster, labels):\n",
    "    print(f\"Silhouette: {silhouette_score(df_to_cluster, labels)}. Higher is better.\")\n",
    "    print(f\"Calinski-Harabasz: {calinski_harabasz_score(df_to_cluster, labels)}. Higher is better.\")\n",
    "    print(f\"Davies-Bouldin: {davies_bouldin_score(df_to_cluster, labels)}. Lower is better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_result(twod_df, cluster_labels):\n",
    "\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    scatter = plt.scatter(twod_df[0], twod_df[1], c = cluster_labels, cmap='plasma', s = 10)\n",
    "\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label='Label {}'.format(label),\n",
    "                                markerfacecolor=scatter.cmap(scatter.norm(label))) for label in unique_labels]\n",
    "\n",
    "    # Add legend to the plot\n",
    "    plt.legend(handles=legend_elements, loc='best')\n",
    "    plt.show()\n",
    "\n",
    "plot_cluster_result(empl_tsne_df, tsne_kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed['tsne_label'] = tsne_kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_grid = sns.FacetGrid(employed, col = 'tsne_label')\n",
    "tsne_grid.map(sns.histplot, 'empl_provides_mh_cov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_with_prev_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_with_prev_tsne_df = pd.DataFrame(TSNE(n_components=2, perplexity=35, random_state=30).fit_transform(get_variance_thr_df(employed_with_prev_encoded, 0.17)))\n",
    "\n",
    "plt.scatter(empl_with_prev_tsne_df[0], empl_with_prev_tsne_df[1], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_with_prev_tsne_kmeans = KMeans(n_clusters=3, n_init='auto')\n",
    "empl_with_prev_tsne_kmeans_labels = empl_with_prev_tsne_kmeans.fit_predict(empl_with_prev_tsne_df)\n",
    "\n",
    "plot_cluster_result(empl_with_prev_tsne_df, empl_with_prev_tsne_kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clustering_scores(empl_with_prev_tsne_df, empl_with_prev_tsne_kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_with_prev['tsne_label'] =empl_with_prev_tsne_kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale =0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_with_prev.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_withprev_grid = sns.FacetGrid(employed_with_prev, col = 'tsne_label')\n",
    "tsne_withprev_grid.map(sns.histplot, 'morelikely_tobringup_ph_over_mh_interview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_with_prev_varselected = get_variance_thr_df(employed_with_prev_encoded, 0.2)\n",
    "employed_with_prev_varselected_pca_df = get_pca_df(employed_with_prev_varselected, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prev = AgglomerativeClustering(n_clusters=3)\n",
    "agg_prev_labels = agg_prev.fit_predict(employed_with_prev_varselected_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clustering_scores(employed_with_prev_varselected_pca_df, agg_prev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clustering_scores(employed_with_prev_varselected_pca_df, KMeans(n_clusters=3, n_init='auto').fit_predict(employed_with_prev_varselected_pca_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
